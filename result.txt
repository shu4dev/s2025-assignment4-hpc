======================================== test session starts ========================================
platform linux -- Python 3.11.8, pytest-7.4.0, pluggy-1.0.0 -- /opt/apps/software/lang/Anaconda3/2024.02-1/bin/python
cachedir: .pytest_cache
rootdir: /mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc
plugins: anyio-4.2.0
collecting ... collected 18 items

cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.0016-ToyModel] FAILED      [  5%]
cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.0016-ToyModelWithTiedWeights] FAILED [ 11%]
cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.0001-ToyModel] FAILED      [ 16%]
cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.0001-ToyModelWithTiedWeights] FAILED [ 22%]
cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.01-ToyModel] FAILED        [ 27%]
cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.01-ToyModelWithTiedWeights] FAILED [ 33%]
cs336-systems/tests/test_ddp_individual_parameters.py::test_DistributedDataParallelIndividualParameters[ToyModel] PASSED [ 38%]
cs336-systems/tests/test_ddp_individual_parameters.py::test_DistributedDataParallelIndividualParameters[ToyModelWithTiedWeights] PASSED [ 44%]
cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_forward_pass_pytorch PASSED                 [ 50%]
cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_forward_pass_triton PASSED                  [ 55%]
cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_backward_x_pytorch PASSED                   [ 61%]
cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_backward_g_pytorch PASSED                   [ 66%]
cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_backward_x_triton PASSED                    [ 72%]
cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_backward_g_triton PASSED                    [ 77%]
cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_autograd_pytorch_forward_backward PASSED    [ 83%]
cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_autograd_triton_forward_backward PASSED     [ 88%]
cs336-systems/tests/test_sharded_optimizer.py::test_sharded_optimizer[ToyModel] FAILED        [ 94%]
cs336-systems/tests/test_sharded_optimizer.py::test_sharded_optimizer[ToyModelWithTiedWeights] FAILED [100%]

============================================= FAILURES ==============================================
_________________________ test_DistributedDataParallelCPU[0.0016-ToyModel] __________________________

bucket_size_mb = 0.0016, model_class = <class 'tests.common.ToyModel'>

    @pytest.mark.parametrize("model_class", [ToyModel, ToyModelWithTiedWeights])
    @pytest.mark.parametrize("bucket_size_mb", [0.0016, 0.0001, 0.01])
    def test_DistributedDataParallelCPU(bucket_size_mb, model_class):
        """
        bucket_size_mb 0.0016 is designed to test the case with 2 buckets (one bucket
        has 2 parameter tensors, the other has 2).
    
        bucket_size_mb 0.0001 is designed to test the case with 3 buckets (each bucket
        has one parameter tensors).
    
        bucket_size_mb 0.01 is designed to test the case with 1 buckets (containing
        3 parameter tensors).
        """
        world_size = 2
>       mp.spawn(
            _test_DistributedDataParallelCPU,
            args=(world_size, bucket_size_mb, model_class),
            nprocs=world_size,
            join=True,
        )

cs336-systems/tests/test_ddp.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:328: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:284: in start_processes
    while not context.join():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <torch.multiprocessing.spawn.ProcessContext object at 0x1551e1f296d0>, timeout = 30

    def join(self, timeout=None):
        r"""Join one or more processes within spawn context.
    
        Attempt to join one or more processes in this spawn context.
        If one of them exited with a non-zero exit status, this function
        kills the remaining processes and raises an exception with the cause
        of the first process exiting.
    
        Returns ``True`` if all processes have been joined successfully,
        ``False`` if there are more processes that need to be joined.
    
        Args:
            timeout (float): Wait this long before giving up on waiting.
        """
        # Ensure this function can be called even when we're done.
        if len(self.sentinels) == 0:
            return True
    
        # Wait for any process to fail or all of them to succeed.
        ready = multiprocessing.connection.wait(
            self.sentinels.keys(),
            timeout=timeout,
        )
    
        error_index = None
        for sentinel in ready:
            index = self.sentinels.pop(sentinel)
            process = self.processes[index]
            process.join()
            if process.exitcode != 0:
                error_index = index
                break
    
        # Return if there was no error.
        if error_index is None:
            # Return whether or not all processes have been joined.
            return len(self.sentinels) == 0
    
        # Assume failure. Terminate processes that are still alive.
        # Try SIGTERM then SIGKILL if the process isn't going down.
        # The reason is related to python signal handling is limited
        # to main thread and if that is in c/c++ land and stuck it won't
        # to handle it. We have seen processes getting stuck not handling
        # SIGTERM for the above reason.
        timeout: int = 30
        for process in self.processes:
            if process.is_alive():
                log.warning("Terminating process %s via signal SIGTERM", process.pid)
                process.terminate()
        end = time.monotonic() + timeout
        for process in self.processes:
            time_to_wait = max(0, end - time.monotonic())
            process.join(time_to_wait)
        for process in self.processes:
            if process.is_alive():
                log.warning(
                    "Unable to shutdown process %s via SIGTERM , forcefully exiting via SIGKILL",
                    process.pid,
                )
                process.kill()
            process.join()
    
        # The file will only be created if the process crashed.
        failed_process = self.processes[error_index]
        if not os.access(self.error_files[error_index], os.R_OK):
            exitcode = self.processes[error_index].exitcode
            if exitcode < 0:
                try:
                    name = signal.Signals(-exitcode).name
                except ValueError:
                    name = f"<Unknown signal {-exitcode}>"
                raise ProcessExitedException(
                    "process %d terminated with signal %s" % (error_index, name),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                    signal_name=name,
                )
            else:
                raise ProcessExitedException(
                    "process %d terminated with exit code %d" % (error_index, exitcode),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                )
    
        with open(self.error_files[error_index], "rb") as fh:
            original_trace = pickle.load(fh)
        msg = "\n\n-- Process %d terminated with the following error:\n" % error_index
        msg += original_trace
>       raise ProcessRaisedException(msg, error_index, failed_process.pid)
E       torch.multiprocessing.spawn.ProcessRaisedException: 
E       
E       -- Process 1 terminated with the following error:
E       Traceback (most recent call last):
E         File "/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 90, in _wrap
E           fn(i, *args)
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/test_ddp.py", line 75, in _test_DistributedDataParallelCPU
E           ddp_model = get_ddp_bucketed(
E                       ^^^^^^^^^^^^^^^^^
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/adapters.py", line 138, in get_ddp_bucketed
E           raise NotImplementedError
E       NotImplementedError

/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:203: ProcessRaisedException
--------------------------------------- Captured stderr call ----------------------------------------
W0509 13:15:17.414000 632079 torch/multiprocessing/spawn.py:160] Terminating process 632120 via signal SIGTERM
__________________ test_DistributedDataParallelCPU[0.0016-ToyModelWithTiedWeights] __________________

bucket_size_mb = 0.0016, model_class = <class 'tests.common.ToyModelWithTiedWeights'>

    @pytest.mark.parametrize("model_class", [ToyModel, ToyModelWithTiedWeights])
    @pytest.mark.parametrize("bucket_size_mb", [0.0016, 0.0001, 0.01])
    def test_DistributedDataParallelCPU(bucket_size_mb, model_class):
        """
        bucket_size_mb 0.0016 is designed to test the case with 2 buckets (one bucket
        has 2 parameter tensors, the other has 2).
    
        bucket_size_mb 0.0001 is designed to test the case with 3 buckets (each bucket
        has one parameter tensors).
    
        bucket_size_mb 0.01 is designed to test the case with 1 buckets (containing
        3 parameter tensors).
        """
        world_size = 2
>       mp.spawn(
            _test_DistributedDataParallelCPU,
            args=(world_size, bucket_size_mb, model_class),
            nprocs=world_size,
            join=True,
        )

cs336-systems/tests/test_ddp.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:328: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:284: in start_processes
    while not context.join():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <torch.multiprocessing.spawn.ProcessContext object at 0x155113672150>, timeout = 30

    def join(self, timeout=None):
        r"""Join one or more processes within spawn context.
    
        Attempt to join one or more processes in this spawn context.
        If one of them exited with a non-zero exit status, this function
        kills the remaining processes and raises an exception with the cause
        of the first process exiting.
    
        Returns ``True`` if all processes have been joined successfully,
        ``False`` if there are more processes that need to be joined.
    
        Args:
            timeout (float): Wait this long before giving up on waiting.
        """
        # Ensure this function can be called even when we're done.
        if len(self.sentinels) == 0:
            return True
    
        # Wait for any process to fail or all of them to succeed.
        ready = multiprocessing.connection.wait(
            self.sentinels.keys(),
            timeout=timeout,
        )
    
        error_index = None
        for sentinel in ready:
            index = self.sentinels.pop(sentinel)
            process = self.processes[index]
            process.join()
            if process.exitcode != 0:
                error_index = index
                break
    
        # Return if there was no error.
        if error_index is None:
            # Return whether or not all processes have been joined.
            return len(self.sentinels) == 0
    
        # Assume failure. Terminate processes that are still alive.
        # Try SIGTERM then SIGKILL if the process isn't going down.
        # The reason is related to python signal handling is limited
        # to main thread and if that is in c/c++ land and stuck it won't
        # to handle it. We have seen processes getting stuck not handling
        # SIGTERM for the above reason.
        timeout: int = 30
        for process in self.processes:
            if process.is_alive():
                log.warning("Terminating process %s via signal SIGTERM", process.pid)
                process.terminate()
        end = time.monotonic() + timeout
        for process in self.processes:
            time_to_wait = max(0, end - time.monotonic())
            process.join(time_to_wait)
        for process in self.processes:
            if process.is_alive():
                log.warning(
                    "Unable to shutdown process %s via SIGTERM , forcefully exiting via SIGKILL",
                    process.pid,
                )
                process.kill()
            process.join()
    
        # The file will only be created if the process crashed.
        failed_process = self.processes[error_index]
        if not os.access(self.error_files[error_index], os.R_OK):
            exitcode = self.processes[error_index].exitcode
            if exitcode < 0:
                try:
                    name = signal.Signals(-exitcode).name
                except ValueError:
                    name = f"<Unknown signal {-exitcode}>"
                raise ProcessExitedException(
                    "process %d terminated with signal %s" % (error_index, name),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                    signal_name=name,
                )
            else:
                raise ProcessExitedException(
                    "process %d terminated with exit code %d" % (error_index, exitcode),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                )
    
        with open(self.error_files[error_index], "rb") as fh:
            original_trace = pickle.load(fh)
        msg = "\n\n-- Process %d terminated with the following error:\n" % error_index
        msg += original_trace
>       raise ProcessRaisedException(msg, error_index, failed_process.pid)
E       torch.multiprocessing.spawn.ProcessRaisedException: 
E       
E       -- Process 1 terminated with the following error:
E       Traceback (most recent call last):
E         File "/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 90, in _wrap
E           fn(i, *args)
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/test_ddp.py", line 75, in _test_DistributedDataParallelCPU
E           ddp_model = get_ddp_bucketed(
E                       ^^^^^^^^^^^^^^^^^
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/adapters.py", line 138, in get_ddp_bucketed
E           raise NotImplementedError
E       NotImplementedError

/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:203: ProcessRaisedException
--------------------------------------- Captured stderr call ----------------------------------------
W0509 13:15:22.305000 632079 torch/multiprocessing/spawn.py:160] Terminating process 632179 via signal SIGTERM
_________________________ test_DistributedDataParallelCPU[0.0001-ToyModel] __________________________

bucket_size_mb = 0.0001, model_class = <class 'tests.common.ToyModel'>

    @pytest.mark.parametrize("model_class", [ToyModel, ToyModelWithTiedWeights])
    @pytest.mark.parametrize("bucket_size_mb", [0.0016, 0.0001, 0.01])
    def test_DistributedDataParallelCPU(bucket_size_mb, model_class):
        """
        bucket_size_mb 0.0016 is designed to test the case with 2 buckets (one bucket
        has 2 parameter tensors, the other has 2).
    
        bucket_size_mb 0.0001 is designed to test the case with 3 buckets (each bucket
        has one parameter tensors).
    
        bucket_size_mb 0.01 is designed to test the case with 1 buckets (containing
        3 parameter tensors).
        """
        world_size = 2
>       mp.spawn(
            _test_DistributedDataParallelCPU,
            args=(world_size, bucket_size_mb, model_class),
            nprocs=world_size,
            join=True,
        )

cs336-systems/tests/test_ddp.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:328: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:284: in start_processes
    while not context.join():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <torch.multiprocessing.spawn.ProcessContext object at 0x1551e1c176d0>, timeout = 30

    def join(self, timeout=None):
        r"""Join one or more processes within spawn context.
    
        Attempt to join one or more processes in this spawn context.
        If one of them exited with a non-zero exit status, this function
        kills the remaining processes and raises an exception with the cause
        of the first process exiting.
    
        Returns ``True`` if all processes have been joined successfully,
        ``False`` if there are more processes that need to be joined.
    
        Args:
            timeout (float): Wait this long before giving up on waiting.
        """
        # Ensure this function can be called even when we're done.
        if len(self.sentinels) == 0:
            return True
    
        # Wait for any process to fail or all of them to succeed.
        ready = multiprocessing.connection.wait(
            self.sentinels.keys(),
            timeout=timeout,
        )
    
        error_index = None
        for sentinel in ready:
            index = self.sentinels.pop(sentinel)
            process = self.processes[index]
            process.join()
            if process.exitcode != 0:
                error_index = index
                break
    
        # Return if there was no error.
        if error_index is None:
            # Return whether or not all processes have been joined.
            return len(self.sentinels) == 0
    
        # Assume failure. Terminate processes that are still alive.
        # Try SIGTERM then SIGKILL if the process isn't going down.
        # The reason is related to python signal handling is limited
        # to main thread and if that is in c/c++ land and stuck it won't
        # to handle it. We have seen processes getting stuck not handling
        # SIGTERM for the above reason.
        timeout: int = 30
        for process in self.processes:
            if process.is_alive():
                log.warning("Terminating process %s via signal SIGTERM", process.pid)
                process.terminate()
        end = time.monotonic() + timeout
        for process in self.processes:
            time_to_wait = max(0, end - time.monotonic())
            process.join(time_to_wait)
        for process in self.processes:
            if process.is_alive():
                log.warning(
                    "Unable to shutdown process %s via SIGTERM , forcefully exiting via SIGKILL",
                    process.pid,
                )
                process.kill()
            process.join()
    
        # The file will only be created if the process crashed.
        failed_process = self.processes[error_index]
        if not os.access(self.error_files[error_index], os.R_OK):
            exitcode = self.processes[error_index].exitcode
            if exitcode < 0:
                try:
                    name = signal.Signals(-exitcode).name
                except ValueError:
                    name = f"<Unknown signal {-exitcode}>"
                raise ProcessExitedException(
                    "process %d terminated with signal %s" % (error_index, name),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                    signal_name=name,
                )
            else:
                raise ProcessExitedException(
                    "process %d terminated with exit code %d" % (error_index, exitcode),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                )
    
        with open(self.error_files[error_index], "rb") as fh:
            original_trace = pickle.load(fh)
        msg = "\n\n-- Process %d terminated with the following error:\n" % error_index
        msg += original_trace
>       raise ProcessRaisedException(msg, error_index, failed_process.pid)
E       torch.multiprocessing.spawn.ProcessRaisedException: 
E       
E       -- Process 1 terminated with the following error:
E       Traceback (most recent call last):
E         File "/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 90, in _wrap
E           fn(i, *args)
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/test_ddp.py", line 75, in _test_DistributedDataParallelCPU
E           ddp_model = get_ddp_bucketed(
E                       ^^^^^^^^^^^^^^^^^
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/adapters.py", line 138, in get_ddp_bucketed
E           raise NotImplementedError
E       NotImplementedError

/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:203: ProcessRaisedException
--------------------------------------- Captured stderr call ----------------------------------------
W0509 13:15:27.183000 632079 torch/multiprocessing/spawn.py:160] Terminating process 632206 via signal SIGTERM
__________________ test_DistributedDataParallelCPU[0.0001-ToyModelWithTiedWeights] __________________

bucket_size_mb = 0.0001, model_class = <class 'tests.common.ToyModelWithTiedWeights'>

    @pytest.mark.parametrize("model_class", [ToyModel, ToyModelWithTiedWeights])
    @pytest.mark.parametrize("bucket_size_mb", [0.0016, 0.0001, 0.01])
    def test_DistributedDataParallelCPU(bucket_size_mb, model_class):
        """
        bucket_size_mb 0.0016 is designed to test the case with 2 buckets (one bucket
        has 2 parameter tensors, the other has 2).
    
        bucket_size_mb 0.0001 is designed to test the case with 3 buckets (each bucket
        has one parameter tensors).
    
        bucket_size_mb 0.01 is designed to test the case with 1 buckets (containing
        3 parameter tensors).
        """
        world_size = 2
>       mp.spawn(
            _test_DistributedDataParallelCPU,
            args=(world_size, bucket_size_mb, model_class),
            nprocs=world_size,
            join=True,
        )

cs336-systems/tests/test_ddp.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:328: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:284: in start_processes
    while not context.join():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <torch.multiprocessing.spawn.ProcessContext object at 0x15510c164610>, timeout = 30

    def join(self, timeout=None):
        r"""Join one or more processes within spawn context.
    
        Attempt to join one or more processes in this spawn context.
        If one of them exited with a non-zero exit status, this function
        kills the remaining processes and raises an exception with the cause
        of the first process exiting.
    
        Returns ``True`` if all processes have been joined successfully,
        ``False`` if there are more processes that need to be joined.
    
        Args:
            timeout (float): Wait this long before giving up on waiting.
        """
        # Ensure this function can be called even when we're done.
        if len(self.sentinels) == 0:
            return True
    
        # Wait for any process to fail or all of them to succeed.
        ready = multiprocessing.connection.wait(
            self.sentinels.keys(),
            timeout=timeout,
        )
    
        error_index = None
        for sentinel in ready:
            index = self.sentinels.pop(sentinel)
            process = self.processes[index]
            process.join()
            if process.exitcode != 0:
                error_index = index
                break
    
        # Return if there was no error.
        if error_index is None:
            # Return whether or not all processes have been joined.
            return len(self.sentinels) == 0
    
        # Assume failure. Terminate processes that are still alive.
        # Try SIGTERM then SIGKILL if the process isn't going down.
        # The reason is related to python signal handling is limited
        # to main thread and if that is in c/c++ land and stuck it won't
        # to handle it. We have seen processes getting stuck not handling
        # SIGTERM for the above reason.
        timeout: int = 30
        for process in self.processes:
            if process.is_alive():
                log.warning("Terminating process %s via signal SIGTERM", process.pid)
                process.terminate()
        end = time.monotonic() + timeout
        for process in self.processes:
            time_to_wait = max(0, end - time.monotonic())
            process.join(time_to_wait)
        for process in self.processes:
            if process.is_alive():
                log.warning(
                    "Unable to shutdown process %s via SIGTERM , forcefully exiting via SIGKILL",
                    process.pid,
                )
                process.kill()
            process.join()
    
        # The file will only be created if the process crashed.
        failed_process = self.processes[error_index]
        if not os.access(self.error_files[error_index], os.R_OK):
            exitcode = self.processes[error_index].exitcode
            if exitcode < 0:
                try:
                    name = signal.Signals(-exitcode).name
                except ValueError:
                    name = f"<Unknown signal {-exitcode}>"
                raise ProcessExitedException(
                    "process %d terminated with signal %s" % (error_index, name),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                    signal_name=name,
                )
            else:
                raise ProcessExitedException(
                    "process %d terminated with exit code %d" % (error_index, exitcode),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                )
    
        with open(self.error_files[error_index], "rb") as fh:
            original_trace = pickle.load(fh)
        msg = "\n\n-- Process %d terminated with the following error:\n" % error_index
        msg += original_trace
>       raise ProcessRaisedException(msg, error_index, failed_process.pid)
E       torch.multiprocessing.spawn.ProcessRaisedException: 
E       
E       -- Process 1 terminated with the following error:
E       Traceback (most recent call last):
E         File "/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 90, in _wrap
E           fn(i, *args)
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/test_ddp.py", line 75, in _test_DistributedDataParallelCPU
E           ddp_model = get_ddp_bucketed(
E                       ^^^^^^^^^^^^^^^^^
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/adapters.py", line 138, in get_ddp_bucketed
E           raise NotImplementedError
E       NotImplementedError

/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:203: ProcessRaisedException
--------------------------------------- Captured stderr call ----------------------------------------
W0509 13:15:32.095000 632079 torch/multiprocessing/spawn.py:160] Terminating process 632228 via signal SIGTERM
__________________________ test_DistributedDataParallelCPU[0.01-ToyModel] ___________________________

bucket_size_mb = 0.01, model_class = <class 'tests.common.ToyModel'>

    @pytest.mark.parametrize("model_class", [ToyModel, ToyModelWithTiedWeights])
    @pytest.mark.parametrize("bucket_size_mb", [0.0016, 0.0001, 0.01])
    def test_DistributedDataParallelCPU(bucket_size_mb, model_class):
        """
        bucket_size_mb 0.0016 is designed to test the case with 2 buckets (one bucket
        has 2 parameter tensors, the other has 2).
    
        bucket_size_mb 0.0001 is designed to test the case with 3 buckets (each bucket
        has one parameter tensors).
    
        bucket_size_mb 0.01 is designed to test the case with 1 buckets (containing
        3 parameter tensors).
        """
        world_size = 2
>       mp.spawn(
            _test_DistributedDataParallelCPU,
            args=(world_size, bucket_size_mb, model_class),
            nprocs=world_size,
            join=True,
        )

cs336-systems/tests/test_ddp.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:328: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:284: in start_processes
    while not context.join():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <torch.multiprocessing.spawn.ProcessContext object at 0x15510c107d10>, timeout = 30

    def join(self, timeout=None):
        r"""Join one or more processes within spawn context.
    
        Attempt to join one or more processes in this spawn context.
        If one of them exited with a non-zero exit status, this function
        kills the remaining processes and raises an exception with the cause
        of the first process exiting.
    
        Returns ``True`` if all processes have been joined successfully,
        ``False`` if there are more processes that need to be joined.
    
        Args:
            timeout (float): Wait this long before giving up on waiting.
        """
        # Ensure this function can be called even when we're done.
        if len(self.sentinels) == 0:
            return True
    
        # Wait for any process to fail or all of them to succeed.
        ready = multiprocessing.connection.wait(
            self.sentinels.keys(),
            timeout=timeout,
        )
    
        error_index = None
        for sentinel in ready:
            index = self.sentinels.pop(sentinel)
            process = self.processes[index]
            process.join()
            if process.exitcode != 0:
                error_index = index
                break
    
        # Return if there was no error.
        if error_index is None:
            # Return whether or not all processes have been joined.
            return len(self.sentinels) == 0
    
        # Assume failure. Terminate processes that are still alive.
        # Try SIGTERM then SIGKILL if the process isn't going down.
        # The reason is related to python signal handling is limited
        # to main thread and if that is in c/c++ land and stuck it won't
        # to handle it. We have seen processes getting stuck not handling
        # SIGTERM for the above reason.
        timeout: int = 30
        for process in self.processes:
            if process.is_alive():
                log.warning("Terminating process %s via signal SIGTERM", process.pid)
                process.terminate()
        end = time.monotonic() + timeout
        for process in self.processes:
            time_to_wait = max(0, end - time.monotonic())
            process.join(time_to_wait)
        for process in self.processes:
            if process.is_alive():
                log.warning(
                    "Unable to shutdown process %s via SIGTERM , forcefully exiting via SIGKILL",
                    process.pid,
                )
                process.kill()
            process.join()
    
        # The file will only be created if the process crashed.
        failed_process = self.processes[error_index]
        if not os.access(self.error_files[error_index], os.R_OK):
            exitcode = self.processes[error_index].exitcode
            if exitcode < 0:
                try:
                    name = signal.Signals(-exitcode).name
                except ValueError:
                    name = f"<Unknown signal {-exitcode}>"
                raise ProcessExitedException(
                    "process %d terminated with signal %s" % (error_index, name),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                    signal_name=name,
                )
            else:
                raise ProcessExitedException(
                    "process %d terminated with exit code %d" % (error_index, exitcode),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                )
    
        with open(self.error_files[error_index], "rb") as fh:
            original_trace = pickle.load(fh)
        msg = "\n\n-- Process %d terminated with the following error:\n" % error_index
        msg += original_trace
>       raise ProcessRaisedException(msg, error_index, failed_process.pid)
E       torch.multiprocessing.spawn.ProcessRaisedException: 
E       
E       -- Process 1 terminated with the following error:
E       Traceback (most recent call last):
E         File "/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 90, in _wrap
E           fn(i, *args)
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/test_ddp.py", line 75, in _test_DistributedDataParallelCPU
E           ddp_model = get_ddp_bucketed(
E                       ^^^^^^^^^^^^^^^^^
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/adapters.py", line 138, in get_ddp_bucketed
E           raise NotImplementedError
E       NotImplementedError

/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:203: ProcessRaisedException
--------------------------------------- Captured stderr call ----------------------------------------
W0509 13:15:36.911000 632079 torch/multiprocessing/spawn.py:160] Terminating process 632256 via signal SIGTERM
___________________ test_DistributedDataParallelCPU[0.01-ToyModelWithTiedWeights] ___________________

bucket_size_mb = 0.01, model_class = <class 'tests.common.ToyModelWithTiedWeights'>

    @pytest.mark.parametrize("model_class", [ToyModel, ToyModelWithTiedWeights])
    @pytest.mark.parametrize("bucket_size_mb", [0.0016, 0.0001, 0.01])
    def test_DistributedDataParallelCPU(bucket_size_mb, model_class):
        """
        bucket_size_mb 0.0016 is designed to test the case with 2 buckets (one bucket
        has 2 parameter tensors, the other has 2).
    
        bucket_size_mb 0.0001 is designed to test the case with 3 buckets (each bucket
        has one parameter tensors).
    
        bucket_size_mb 0.01 is designed to test the case with 1 buckets (containing
        3 parameter tensors).
        """
        world_size = 2
>       mp.spawn(
            _test_DistributedDataParallelCPU,
            args=(world_size, bucket_size_mb, model_class),
            nprocs=world_size,
            join=True,
        )

cs336-systems/tests/test_ddp.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:328: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:284: in start_processes
    while not context.join():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <torch.multiprocessing.spawn.ProcessContext object at 0x15510870dfd0>, timeout = 30

    def join(self, timeout=None):
        r"""Join one or more processes within spawn context.
    
        Attempt to join one or more processes in this spawn context.
        If one of them exited with a non-zero exit status, this function
        kills the remaining processes and raises an exception with the cause
        of the first process exiting.
    
        Returns ``True`` if all processes have been joined successfully,
        ``False`` if there are more processes that need to be joined.
    
        Args:
            timeout (float): Wait this long before giving up on waiting.
        """
        # Ensure this function can be called even when we're done.
        if len(self.sentinels) == 0:
            return True
    
        # Wait for any process to fail or all of them to succeed.
        ready = multiprocessing.connection.wait(
            self.sentinels.keys(),
            timeout=timeout,
        )
    
        error_index = None
        for sentinel in ready:
            index = self.sentinels.pop(sentinel)
            process = self.processes[index]
            process.join()
            if process.exitcode != 0:
                error_index = index
                break
    
        # Return if there was no error.
        if error_index is None:
            # Return whether or not all processes have been joined.
            return len(self.sentinels) == 0
    
        # Assume failure. Terminate processes that are still alive.
        # Try SIGTERM then SIGKILL if the process isn't going down.
        # The reason is related to python signal handling is limited
        # to main thread and if that is in c/c++ land and stuck it won't
        # to handle it. We have seen processes getting stuck not handling
        # SIGTERM for the above reason.
        timeout: int = 30
        for process in self.processes:
            if process.is_alive():
                log.warning("Terminating process %s via signal SIGTERM", process.pid)
                process.terminate()
        end = time.monotonic() + timeout
        for process in self.processes:
            time_to_wait = max(0, end - time.monotonic())
            process.join(time_to_wait)
        for process in self.processes:
            if process.is_alive():
                log.warning(
                    "Unable to shutdown process %s via SIGTERM , forcefully exiting via SIGKILL",
                    process.pid,
                )
                process.kill()
            process.join()
    
        # The file will only be created if the process crashed.
        failed_process = self.processes[error_index]
        if not os.access(self.error_files[error_index], os.R_OK):
            exitcode = self.processes[error_index].exitcode
            if exitcode < 0:
                try:
                    name = signal.Signals(-exitcode).name
                except ValueError:
                    name = f"<Unknown signal {-exitcode}>"
                raise ProcessExitedException(
                    "process %d terminated with signal %s" % (error_index, name),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                    signal_name=name,
                )
            else:
                raise ProcessExitedException(
                    "process %d terminated with exit code %d" % (error_index, exitcode),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                )
    
        with open(self.error_files[error_index], "rb") as fh:
            original_trace = pickle.load(fh)
        msg = "\n\n-- Process %d terminated with the following error:\n" % error_index
        msg += original_trace
>       raise ProcessRaisedException(msg, error_index, failed_process.pid)
E       torch.multiprocessing.spawn.ProcessRaisedException: 
E       
E       -- Process 1 terminated with the following error:
E       Traceback (most recent call last):
E         File "/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 90, in _wrap
E           fn(i, *args)
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/test_ddp.py", line 75, in _test_DistributedDataParallelCPU
E           ddp_model = get_ddp_bucketed(
E                       ^^^^^^^^^^^^^^^^^
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/adapters.py", line 138, in get_ddp_bucketed
E           raise NotImplementedError
E       NotImplementedError

/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:203: ProcessRaisedException
--------------------------------------- Captured stderr call ----------------------------------------
W0509 13:15:41.848000 632079 torch/multiprocessing/spawn.py:160] Terminating process 632277 via signal SIGTERM
_________________________________ test_sharded_optimizer[ToyModel] __________________________________

model_class = <class 'tests.common.ToyModel'>

    @pytest.mark.parametrize("model_class", [ToyModel, ToyModelWithTiedWeights])
    def test_sharded_optimizer(model_class):
        world_size = 2
>       mp.spawn(
            _test_sharded_optimizer,
            args=(world_size, model_class),
            nprocs=world_size,
            join=True,
        )

cs336-systems/tests/test_sharded_optimizer.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:328: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:284: in start_processes
    while not context.join():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <torch.multiprocessing.spawn.ProcessContext object at 0x1550df78c950>, timeout = 30

    def join(self, timeout=None):
        r"""Join one or more processes within spawn context.
    
        Attempt to join one or more processes in this spawn context.
        If one of them exited with a non-zero exit status, this function
        kills the remaining processes and raises an exception with the cause
        of the first process exiting.
    
        Returns ``True`` if all processes have been joined successfully,
        ``False`` if there are more processes that need to be joined.
    
        Args:
            timeout (float): Wait this long before giving up on waiting.
        """
        # Ensure this function can be called even when we're done.
        if len(self.sentinels) == 0:
            return True
    
        # Wait for any process to fail or all of them to succeed.
        ready = multiprocessing.connection.wait(
            self.sentinels.keys(),
            timeout=timeout,
        )
    
        error_index = None
        for sentinel in ready:
            index = self.sentinels.pop(sentinel)
            process = self.processes[index]
            process.join()
            if process.exitcode != 0:
                error_index = index
                break
    
        # Return if there was no error.
        if error_index is None:
            # Return whether or not all processes have been joined.
            return len(self.sentinels) == 0
    
        # Assume failure. Terminate processes that are still alive.
        # Try SIGTERM then SIGKILL if the process isn't going down.
        # The reason is related to python signal handling is limited
        # to main thread and if that is in c/c++ land and stuck it won't
        # to handle it. We have seen processes getting stuck not handling
        # SIGTERM for the above reason.
        timeout: int = 30
        for process in self.processes:
            if process.is_alive():
                log.warning("Terminating process %s via signal SIGTERM", process.pid)
                process.terminate()
        end = time.monotonic() + timeout
        for process in self.processes:
            time_to_wait = max(0, end - time.monotonic())
            process.join(time_to_wait)
        for process in self.processes:
            if process.is_alive():
                log.warning(
                    "Unable to shutdown process %s via SIGTERM , forcefully exiting via SIGKILL",
                    process.pid,
                )
                process.kill()
            process.join()
    
        # The file will only be created if the process crashed.
        failed_process = self.processes[error_index]
        if not os.access(self.error_files[error_index], os.R_OK):
            exitcode = self.processes[error_index].exitcode
            if exitcode < 0:
                try:
                    name = signal.Signals(-exitcode).name
                except ValueError:
                    name = f"<Unknown signal {-exitcode}>"
                raise ProcessExitedException(
                    "process %d terminated with signal %s" % (error_index, name),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                    signal_name=name,
                )
            else:
                raise ProcessExitedException(
                    "process %d terminated with exit code %d" % (error_index, exitcode),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                )
    
        with open(self.error_files[error_index], "rb") as fh:
            original_trace = pickle.load(fh)
        msg = "\n\n-- Process %d terminated with the following error:\n" % error_index
        msg += original_trace
>       raise ProcessRaisedException(msg, error_index, failed_process.pid)
E       torch.multiprocessing.spawn.ProcessRaisedException: 
E       
E       -- Process 1 terminated with the following error:
E       Traceback (most recent call last):
E         File "/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 90, in _wrap
E           fn(i, *args)
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/test_sharded_optimizer.py", line 48, in _test_sharded_optimizer
E           sharded_optimizer = get_sharded_optimizer(
E                               ^^^^^^^^^^^^^^^^^^^^^^
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/adapters.py", line 191, in get_sharded_optimizer
E           raise NotImplementedError
E       NotImplementedError

/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:203: ProcessRaisedException
--------------------------------------- Captured stderr call ----------------------------------------
W0509 13:16:05.187000 632079 torch/multiprocessing/spawn.py:160] Terminating process 632395 via signal SIGTERM
__________________________ test_sharded_optimizer[ToyModelWithTiedWeights] __________________________

model_class = <class 'tests.common.ToyModelWithTiedWeights'>

    @pytest.mark.parametrize("model_class", [ToyModel, ToyModelWithTiedWeights])
    def test_sharded_optimizer(model_class):
        world_size = 2
>       mp.spawn(
            _test_sharded_optimizer,
            args=(world_size, model_class),
            nprocs=world_size,
            join=True,
        )

cs336-systems/tests/test_sharded_optimizer.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:328: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:284: in start_processes
    while not context.join():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <torch.multiprocessing.spawn.ProcessContext object at 0x1550df516450>, timeout = 30

    def join(self, timeout=None):
        r"""Join one or more processes within spawn context.
    
        Attempt to join one or more processes in this spawn context.
        If one of them exited with a non-zero exit status, this function
        kills the remaining processes and raises an exception with the cause
        of the first process exiting.
    
        Returns ``True`` if all processes have been joined successfully,
        ``False`` if there are more processes that need to be joined.
    
        Args:
            timeout (float): Wait this long before giving up on waiting.
        """
        # Ensure this function can be called even when we're done.
        if len(self.sentinels) == 0:
            return True
    
        # Wait for any process to fail or all of them to succeed.
        ready = multiprocessing.connection.wait(
            self.sentinels.keys(),
            timeout=timeout,
        )
    
        error_index = None
        for sentinel in ready:
            index = self.sentinels.pop(sentinel)
            process = self.processes[index]
            process.join()
            if process.exitcode != 0:
                error_index = index
                break
    
        # Return if there was no error.
        if error_index is None:
            # Return whether or not all processes have been joined.
            return len(self.sentinels) == 0
    
        # Assume failure. Terminate processes that are still alive.
        # Try SIGTERM then SIGKILL if the process isn't going down.
        # The reason is related to python signal handling is limited
        # to main thread and if that is in c/c++ land and stuck it won't
        # to handle it. We have seen processes getting stuck not handling
        # SIGTERM for the above reason.
        timeout: int = 30
        for process in self.processes:
            if process.is_alive():
                log.warning("Terminating process %s via signal SIGTERM", process.pid)
                process.terminate()
        end = time.monotonic() + timeout
        for process in self.processes:
            time_to_wait = max(0, end - time.monotonic())
            process.join(time_to_wait)
        for process in self.processes:
            if process.is_alive():
                log.warning(
                    "Unable to shutdown process %s via SIGTERM , forcefully exiting via SIGKILL",
                    process.pid,
                )
                process.kill()
            process.join()
    
        # The file will only be created if the process crashed.
        failed_process = self.processes[error_index]
        if not os.access(self.error_files[error_index], os.R_OK):
            exitcode = self.processes[error_index].exitcode
            if exitcode < 0:
                try:
                    name = signal.Signals(-exitcode).name
                except ValueError:
                    name = f"<Unknown signal {-exitcode}>"
                raise ProcessExitedException(
                    "process %d terminated with signal %s" % (error_index, name),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                    signal_name=name,
                )
            else:
                raise ProcessExitedException(
                    "process %d terminated with exit code %d" % (error_index, exitcode),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                )
    
        with open(self.error_files[error_index], "rb") as fh:
            original_trace = pickle.load(fh)
        msg = "\n\n-- Process %d terminated with the following error:\n" % error_index
        msg += original_trace
>       raise ProcessRaisedException(msg, error_index, failed_process.pid)
E       torch.multiprocessing.spawn.ProcessRaisedException: 
E       
E       -- Process 1 terminated with the following error:
E       Traceback (most recent call last):
E         File "/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 90, in _wrap
E           fn(i, *args)
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/test_sharded_optimizer.py", line 48, in _test_sharded_optimizer
E           sharded_optimizer = get_sharded_optimizer(
E                               ^^^^^^^^^^^^^^^^^^^^^^
E         File "/mnt/lustre/koa/scratch/shu4/s2025-assignment4-hpc/cs336-systems/tests/adapters.py", line 191, in get_sharded_optimizer
E           raise NotImplementedError
E       NotImplementedError

/home/shu4/.local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:203: ProcessRaisedException
--------------------------------------- Captured stderr call ----------------------------------------
W0509 13:16:12.108000 632079 torch/multiprocessing/spawn.py:160] Terminating process 632423 via signal SIGTERM
====================================== short test summary info ======================================
FAILED cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.0016-ToyModel] - torch.m...
FAILED cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.0016-ToyModelWithTiedWeights]
FAILED cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.0001-ToyModel] - torch.m...
FAILED cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.0001-ToyModelWithTiedWeights]
FAILED cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.01-ToyModel] - torch.mul...
FAILED cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.01-ToyModelWithTiedWeights]
FAILED cs336-systems/tests/test_sharded_optimizer.py::test_sharded_optimizer[ToyModel] - torch.mul...
FAILED cs336-systems/tests/test_sharded_optimizer.py::test_sharded_optimizer[ToyModelWithTiedWeights]
============================== 8 failed, 10 passed in 66.96s (0:01:06) ==============================

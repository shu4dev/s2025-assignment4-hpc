{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsnlzghxZmai",
        "outputId": "27a44a57-dea5-4df9-e7b7-afe46ee21d4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 's2025-assignment4-hpc'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 169 (delta 55), reused 61 (delta 52), pack-reused 96 (from 1)\u001b[K\n",
            "Receiving objects: 100% (169/169), 1.68 MiB | 1021.00 KiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n",
            "/content/s2025-assignment4-hpc\n",
            "Already up to date.\n",
            "error: pathspec 'main' did not match any file(s) known to git\n",
            "Obtaining file:///content/s2025-assignment4-hpc/cs336-basics\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Obtaining file:///content/s2025-assignment4-hpc/cs336-systems\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from cs336_basics==0.1.7.dev0) (2024.11.6)\n",
            "Collecting torch==2.2.1 (from cs336_basics==0.1.7.dev0)\n",
            "  Downloading torch-2.2.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cs336_basics==0.1.7.dev0) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->cs336_basics==0.1.7.dev0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->cs336_basics==0.1.7.dev0) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->cs336_basics==0.1.7.dev0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->cs336_basics==0.1.7.dev0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->cs336_basics==0.1.7.dev0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->cs336_basics==0.1.7.dev0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->cs336_basics==0.1.7.dev0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->cs336_basics==0.1.7.dev0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->cs336_basics==0.1.7.dev0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->cs336_basics==0.1.7.dev0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->cs336_basics==0.1.7.dev0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->cs336_basics==0.1.7.dev0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->cs336_basics==0.1.7.dev0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->cs336_basics==0.1.7.dev0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->cs336_basics==0.1.7.dev0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->cs336_basics==0.1.7.dev0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->cs336_basics==0.1.7.dev0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.1->cs336_basics==0.1.7.dev0)\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->cs336_basics==0.1.7.dev0) (12.5.82)\n",
            "Collecting HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix (from cs336_systems==0.0.4.dev0)\n",
            "  Cloning https://github.com/nelson-liu/HolisticTraceAnalysis.git (to revision comm_kernel_fix) to /tmp/pip-install-zxplq9pz/holistictraceanalysis_fe448f5c47c342c992bf10ff3a3848b4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/nelson-liu/HolisticTraceAnalysis.git /tmp/pip-install-zxplq9pz/holistictraceanalysis_fe448f5c47c342c992bf10ff3a3848b4\n",
            "  Running command git checkout -b comm_kernel_fix --track origin/comm_kernel_fix\n",
            "  Switched to a new branch 'comm_kernel_fix'\n",
            "  Branch 'comm_kernel_fix' set up to track remote branch 'comm_kernel_fix' from 'origin'.\n",
            "  Resolved https://github.com/nelson-liu/HolisticTraceAnalysis.git to commit 0d1381ac0f46e26cabae2b9970257c8370ac35a0\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from cs336_systems==0.0.4.dev0) (3.10.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from cs336_systems==0.0.4.dev0) (8.3.5)\n",
            "Collecting jupyterlab>=3.5.1 (from HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading jupyterlab-4.4.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: pandas>=1.5.2 in /usr/local/lib/python3.11/dist-packages (from HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (2.2.2)\n",
            "Requirement already satisfied: plotly>=5.11.0 in /usr/local/lib/python3.11/dist-packages (from HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (5.24.1)\n",
            "Requirement already satisfied: pydot>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (3.0.4)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->cs336_systems==0.0.4.dev0) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest->cs336_systems==0.0.4.dev0) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->cs336_systems==0.0.4.dev0) (1.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cs336_systems==0.0.4.dev0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cs336_systems==0.0.4.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cs336_systems==0.0.4.dev0) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cs336_systems==0.0.4.dev0) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cs336_systems==0.0.4.dev0) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cs336_systems==0.0.4.dev0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cs336_systems==0.0.4.dev0) (2.9.0.post0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.28.1)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (6.17.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (75.2.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (5.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.1->cs336_basics==0.1.7.dev0) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.2->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.2->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.11.0->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (9.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->cs336_systems==0.0.4.dev0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.1->cs336_basics==0.1.7.dev0) (1.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.16.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (23.1.0)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.21.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (1.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (4.3.7)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (2.32.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (21.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.24.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (2.21.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (2.4.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.8.4)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (24.11.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (0.2.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0) (2.22)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3.5.1->HolisticTraceAnalysis@ git+https://github.com/nelson-liu/HolisticTraceAnalysis.git@comm_kernel_fix->cs336_systems==0.0.4.dev0)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading torch-2.2.1-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.4.2-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: HolisticTraceAnalysis\n",
            "  Building wheel for HolisticTraceAnalysis (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for HolisticTraceAnalysis: filename=holistictraceanalysis-0.2.0-py3-none-any.whl size=346338 sha256=a572fe013b5f98994dffc15306e26fa89a0a8a5b8593313ffce8fefc66fcec29\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4gj2ejzk/wheels/67/03/4f/086af4d3b7027d1fb5f99c55c40ef532a3d82b8b37805ed286\n",
            "Successfully built HolisticTraceAnalysis\n",
            "Installing collected packages: uri-template, types-python-dateutil, triton, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, json5, jedi, fqdn, async-lru, nvidia-cusolver-cu12, nvidia-cudnn-cu12, jupyter-server-terminals, jupyter-client, arrow, torch, isoduration, cs336_basics, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, HolisticTraceAnalysis, cs336_systems\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Running setup.py develop for cs336_basics\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "  Running setup.py develop for cs336_systems\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.1 which is incompatible.\n",
            "notebook 6.5.7 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed HolisticTraceAnalysis-0.2.0 arrow-1.3.0 async-lru-2.0.5 cs336_basics-0.1.7.dev0 cs336_systems-0.0.4.dev0 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.2 json5-0.12.0 jupyter-client-8.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.2 jupyterlab-server-2.27.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 overrides-7.7.0 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 torch-2.2.1 triton-2.2.0 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shu4dev/s2025-assignment4-hpc.git\n",
        "%cd s2025-assignment4-hpc\n",
        "!git pull\n",
        "!git checkout main\n",
        "!pip install -e ./cs336-basics/ -e ./cs336-systems/'[test]'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFRYKTaraXlj",
        "outputId": "e6cb4505-d82d-4cd8-9c41-444c23ad087b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.11.12, pytest-8.3.5, pluggy-1.5.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/s2025-assignment4-hpc\n",
            "plugins: langsmith-0.3.39, anyio-4.9.0, typeguard-4.4.2\n",
            "collected 18 items                                                             \u001b[0m\n",
            "\n",
            "cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.0016-ToyModel] \u001b[31mFAILED\u001b[0m\u001b[31m [  5%]\u001b[0m\n",
            "cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.0016-ToyModelWithTiedWeights] \u001b[31mFAILED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
            "cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.0001-ToyModel] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
            "cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.0001-ToyModelWithTiedWeights] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
            "cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.01-ToyModel] \u001b[31mFAILED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
            "cs336-systems/tests/test_ddp.py::test_DistributedDataParallelCPU[0.01-ToyModelWithTiedWeights] \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
            "cs336-systems/tests/test_ddp_individual_parameters.py::test_DistributedDataParallelIndividualParameters[ToyModel] \u001b[32mPASSED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
            "cs336-systems/tests/test_ddp_individual_parameters.py::test_DistributedDataParallelIndividualParameters[ToyModelWithTiedWeights] \u001b[32mPASSED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
            "cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_forward_pass_pytorch \u001b[32mPASSED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
            "cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_forward_pass_triton \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
            "cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_backward_x_pytorch \u001b[32mPASSED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
            "cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_backward_g_pytorch \u001b[32mPASSED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
            "cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_backward_x_triton \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
            "cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_backward_g_triton \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
            "cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_autograd_pytorch_forward_backward \u001b[32mPASSED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
            "cs336-systems/tests/test_rmsnorm.py::test_rmsnorm_autograd_triton_forward_backward \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
            "cs336-systems/tests/test_sharded_optimizer.py::test_sharded_optimizer[ToyModel] \u001b[31mFAILED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
            "cs336-systems/tests/test_sharded_optimizer.py::test_sharded_optimizer[ToyModelWithTiedWeights] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_______________ test_DistributedDataParallelCPU[0.0016-ToyModel] _______________\u001b[0m\n",
            "\n",
            "bucket_size_mb = 0.0016, model_class = <class 'tests.common.ToyModel'>\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_class\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [ToyModel, ToyModelWithTiedWeights])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbucket_size_mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94m0.0016\u001b[39;49;00m, \u001b[94m0.0001\u001b[39;49;00m, \u001b[94m0.01\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_DistributedDataParallelCPU\u001b[39;49;00m(bucket_size_mb, model_class):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.0016 is designed to test the case with 2 buckets (one bucket\u001b[39;49;00m\n",
            "    \u001b[33m    has 2 parameter tensors, the other has 2).\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.0001 is designed to test the case with 3 buckets (each bucket\u001b[39;49;00m\n",
            "    \u001b[33m    has one parameter tensors).\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.01 is designed to test the case with 1 buckets (containing\u001b[39;49;00m\n",
            "    \u001b[33m    3 parameter tensors).\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        world_size = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       mp.spawn(\u001b[90m\u001b[39;49;00m\n",
            "            _test_DistributedDataParallelCPU,\u001b[90m\u001b[39;49;00m\n",
            "            args=(world_size, bucket_size_mb, model_class),\u001b[90m\u001b[39;49;00m\n",
            "            nprocs=world_size,\u001b[90m\u001b[39;49;00m\n",
            "            join=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mcs336-systems/tests/test_ddp.py\u001b[0m:44: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:241: in spawn\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m start_processes(fn, args, nprocs, join, daemon, start_method=\u001b[33m\"\u001b[39;49;00m\u001b[33mspawn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:197: in start_processes\n",
            "    \u001b[0m\u001b[94mwhile\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m context.join():\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <torch.multiprocessing.spawn.ProcessContext object at 0x78645acf5250>\n",
            "timeout = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mjoin\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, timeout=\u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\"\"Join one or more processes within spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Attempt to join one or more processes in this spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m    If one of them exited with a non-zero exit status, this function\u001b[39;49;00m\n",
            "    \u001b[33m    kills the remaining processes and raises an exception with the cause\u001b[39;49;00m\n",
            "    \u001b[33m    of the first process exiting.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Returns ``True`` if all processes have been joined successfully,\u001b[39;49;00m\n",
            "    \u001b[33m    ``False`` if there are more processes that need to be joined.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Args:\u001b[39;49;00m\n",
            "    \u001b[33m        timeout (float): Wait this long before giving up on waiting.\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Ensure this function can be called even when we're done.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Wait for any process to fail or all of them to succeed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ready = multiprocessing.connection.wait(\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[96mself\u001b[39;49;00m.sentinels.keys(),\u001b[90m\u001b[39;49;00m\n",
            "            timeout=timeout,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        error_index = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m sentinel \u001b[95min\u001b[39;49;00m ready:\u001b[90m\u001b[39;49;00m\n",
            "            index = \u001b[96mself\u001b[39;49;00m.sentinels.pop(sentinel)\u001b[90m\u001b[39;49;00m\n",
            "            process = \u001b[96mself\u001b[39;49;00m.processes[index]\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.exitcode != \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                error_index = index\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mbreak\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Return if there was no error.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m error_index \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# Return whether or not all processes have been joined.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Assume failure. Terminate processes that are still alive.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
            "                process.terminate()\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# There won't be an error on the queue if the process crashed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        failed_process = \u001b[96mself\u001b[39;49;00m.processes[error_index]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.error_queues[error_index].empty():\u001b[90m\u001b[39;49;00m\n",
            "            exitcode = \u001b[96mself\u001b[39;49;00m.processes[error_index].exitcode\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m exitcode < \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                name = signal.Signals(-exitcode).name\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with signal \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, name),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                    signal_name=name,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with exit code \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, exitcode),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        original_trace = \u001b[96mself\u001b[39;49;00m.error_queues[error_index].get()\u001b[90m\u001b[39;49;00m\n",
            "        msg = \u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m-- Process \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with the following error:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % error_index\u001b[90m\u001b[39;49;00m\n",
            "        msg += original_trace\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m ProcessRaisedException(msg, error_index, failed_process.pid)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       torch.multiprocessing.spawn.ProcessRaisedException: \u001b[0m\n",
            "\u001b[1m\u001b[31mE       \u001b[0m\n",
            "\u001b[1m\u001b[31mE       -- Process 1 terminated with the following error:\u001b[0m\n",
            "\u001b[1m\u001b[31mE       Traceback (most recent call last):\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\u001b[0m\n",
            "\u001b[1m\u001b[31mE           fn(i, *args)\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/test_ddp.py\", line 75, in _test_DistributedDataParallelCPU\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ddp_model = get_ddp_bucketed(\u001b[0m\n",
            "\u001b[1m\u001b[31mE                       ^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/adapters.py\", line 138, in get_ddp_bucketed\u001b[0m\n",
            "\u001b[1m\u001b[31mE           raise NotImplementedError\u001b[0m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:158: ProcessRaisedException\n",
            "----------------------------- Captured stderr call -----------------------------\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\u001b[31m\u001b[1m_______ test_DistributedDataParallelCPU[0.0016-ToyModelWithTiedWeights] ________\u001b[0m\n",
            "\n",
            "bucket_size_mb = 0.0016\n",
            "model_class = <class 'tests.common.ToyModelWithTiedWeights'>\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_class\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [ToyModel, ToyModelWithTiedWeights])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbucket_size_mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94m0.0016\u001b[39;49;00m, \u001b[94m0.0001\u001b[39;49;00m, \u001b[94m0.01\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_DistributedDataParallelCPU\u001b[39;49;00m(bucket_size_mb, model_class):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.0016 is designed to test the case with 2 buckets (one bucket\u001b[39;49;00m\n",
            "    \u001b[33m    has 2 parameter tensors, the other has 2).\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.0001 is designed to test the case with 3 buckets (each bucket\u001b[39;49;00m\n",
            "    \u001b[33m    has one parameter tensors).\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.01 is designed to test the case with 1 buckets (containing\u001b[39;49;00m\n",
            "    \u001b[33m    3 parameter tensors).\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        world_size = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       mp.spawn(\u001b[90m\u001b[39;49;00m\n",
            "            _test_DistributedDataParallelCPU,\u001b[90m\u001b[39;49;00m\n",
            "            args=(world_size, bucket_size_mb, model_class),\u001b[90m\u001b[39;49;00m\n",
            "            nprocs=world_size,\u001b[90m\u001b[39;49;00m\n",
            "            join=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mcs336-systems/tests/test_ddp.py\u001b[0m:44: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:241: in spawn\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m start_processes(fn, args, nprocs, join, daemon, start_method=\u001b[33m\"\u001b[39;49;00m\u001b[33mspawn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:197: in start_processes\n",
            "    \u001b[0m\u001b[94mwhile\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m context.join():\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <torch.multiprocessing.spawn.ProcessContext object at 0x78645aeac9d0>\n",
            "timeout = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mjoin\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, timeout=\u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\"\"Join one or more processes within spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Attempt to join one or more processes in this spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m    If one of them exited with a non-zero exit status, this function\u001b[39;49;00m\n",
            "    \u001b[33m    kills the remaining processes and raises an exception with the cause\u001b[39;49;00m\n",
            "    \u001b[33m    of the first process exiting.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Returns ``True`` if all processes have been joined successfully,\u001b[39;49;00m\n",
            "    \u001b[33m    ``False`` if there are more processes that need to be joined.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Args:\u001b[39;49;00m\n",
            "    \u001b[33m        timeout (float): Wait this long before giving up on waiting.\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Ensure this function can be called even when we're done.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Wait for any process to fail or all of them to succeed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ready = multiprocessing.connection.wait(\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[96mself\u001b[39;49;00m.sentinels.keys(),\u001b[90m\u001b[39;49;00m\n",
            "            timeout=timeout,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        error_index = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m sentinel \u001b[95min\u001b[39;49;00m ready:\u001b[90m\u001b[39;49;00m\n",
            "            index = \u001b[96mself\u001b[39;49;00m.sentinels.pop(sentinel)\u001b[90m\u001b[39;49;00m\n",
            "            process = \u001b[96mself\u001b[39;49;00m.processes[index]\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.exitcode != \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                error_index = index\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mbreak\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Return if there was no error.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m error_index \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# Return whether or not all processes have been joined.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Assume failure. Terminate processes that are still alive.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
            "                process.terminate()\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# There won't be an error on the queue if the process crashed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        failed_process = \u001b[96mself\u001b[39;49;00m.processes[error_index]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.error_queues[error_index].empty():\u001b[90m\u001b[39;49;00m\n",
            "            exitcode = \u001b[96mself\u001b[39;49;00m.processes[error_index].exitcode\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m exitcode < \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                name = signal.Signals(-exitcode).name\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with signal \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, name),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                    signal_name=name,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with exit code \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, exitcode),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        original_trace = \u001b[96mself\u001b[39;49;00m.error_queues[error_index].get()\u001b[90m\u001b[39;49;00m\n",
            "        msg = \u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m-- Process \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with the following error:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % error_index\u001b[90m\u001b[39;49;00m\n",
            "        msg += original_trace\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m ProcessRaisedException(msg, error_index, failed_process.pid)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       torch.multiprocessing.spawn.ProcessRaisedException: \u001b[0m\n",
            "\u001b[1m\u001b[31mE       \u001b[0m\n",
            "\u001b[1m\u001b[31mE       -- Process 1 terminated with the following error:\u001b[0m\n",
            "\u001b[1m\u001b[31mE       Traceback (most recent call last):\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\u001b[0m\n",
            "\u001b[1m\u001b[31mE           fn(i, *args)\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/test_ddp.py\", line 75, in _test_DistributedDataParallelCPU\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ddp_model = get_ddp_bucketed(\u001b[0m\n",
            "\u001b[1m\u001b[31mE                       ^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/adapters.py\", line 138, in get_ddp_bucketed\u001b[0m\n",
            "\u001b[1m\u001b[31mE           raise NotImplementedError\u001b[0m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:158: ProcessRaisedException\n",
            "----------------------------- Captured stderr call -----------------------------\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:12355 (errno: 99 - Cannot assign requested address).\n",
            "\u001b[31m\u001b[1m_______________ test_DistributedDataParallelCPU[0.0001-ToyModel] _______________\u001b[0m\n",
            "\n",
            "bucket_size_mb = 0.0001, model_class = <class 'tests.common.ToyModel'>\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_class\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [ToyModel, ToyModelWithTiedWeights])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbucket_size_mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94m0.0016\u001b[39;49;00m, \u001b[94m0.0001\u001b[39;49;00m, \u001b[94m0.01\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_DistributedDataParallelCPU\u001b[39;49;00m(bucket_size_mb, model_class):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.0016 is designed to test the case with 2 buckets (one bucket\u001b[39;49;00m\n",
            "    \u001b[33m    has 2 parameter tensors, the other has 2).\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.0001 is designed to test the case with 3 buckets (each bucket\u001b[39;49;00m\n",
            "    \u001b[33m    has one parameter tensors).\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.01 is designed to test the case with 1 buckets (containing\u001b[39;49;00m\n",
            "    \u001b[33m    3 parameter tensors).\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        world_size = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       mp.spawn(\u001b[90m\u001b[39;49;00m\n",
            "            _test_DistributedDataParallelCPU,\u001b[90m\u001b[39;49;00m\n",
            "            args=(world_size, bucket_size_mb, model_class),\u001b[90m\u001b[39;49;00m\n",
            "            nprocs=world_size,\u001b[90m\u001b[39;49;00m\n",
            "            join=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mcs336-systems/tests/test_ddp.py\u001b[0m:44: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:241: in spawn\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m start_processes(fn, args, nprocs, join, daemon, start_method=\u001b[33m\"\u001b[39;49;00m\u001b[33mspawn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:197: in start_processes\n",
            "    \u001b[0m\u001b[94mwhile\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m context.join():\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <torch.multiprocessing.spawn.ProcessContext object at 0x78645acde610>\n",
            "timeout = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mjoin\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, timeout=\u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\"\"Join one or more processes within spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Attempt to join one or more processes in this spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m    If one of them exited with a non-zero exit status, this function\u001b[39;49;00m\n",
            "    \u001b[33m    kills the remaining processes and raises an exception with the cause\u001b[39;49;00m\n",
            "    \u001b[33m    of the first process exiting.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Returns ``True`` if all processes have been joined successfully,\u001b[39;49;00m\n",
            "    \u001b[33m    ``False`` if there are more processes that need to be joined.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Args:\u001b[39;49;00m\n",
            "    \u001b[33m        timeout (float): Wait this long before giving up on waiting.\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Ensure this function can be called even when we're done.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Wait for any process to fail or all of them to succeed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ready = multiprocessing.connection.wait(\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[96mself\u001b[39;49;00m.sentinels.keys(),\u001b[90m\u001b[39;49;00m\n",
            "            timeout=timeout,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        error_index = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m sentinel \u001b[95min\u001b[39;49;00m ready:\u001b[90m\u001b[39;49;00m\n",
            "            index = \u001b[96mself\u001b[39;49;00m.sentinels.pop(sentinel)\u001b[90m\u001b[39;49;00m\n",
            "            process = \u001b[96mself\u001b[39;49;00m.processes[index]\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.exitcode != \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                error_index = index\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mbreak\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Return if there was no error.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m error_index \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# Return whether or not all processes have been joined.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Assume failure. Terminate processes that are still alive.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
            "                process.terminate()\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# There won't be an error on the queue if the process crashed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        failed_process = \u001b[96mself\u001b[39;49;00m.processes[error_index]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.error_queues[error_index].empty():\u001b[90m\u001b[39;49;00m\n",
            "            exitcode = \u001b[96mself\u001b[39;49;00m.processes[error_index].exitcode\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m exitcode < \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                name = signal.Signals(-exitcode).name\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with signal \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, name),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                    signal_name=name,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with exit code \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, exitcode),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        original_trace = \u001b[96mself\u001b[39;49;00m.error_queues[error_index].get()\u001b[90m\u001b[39;49;00m\n",
            "        msg = \u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m-- Process \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with the following error:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % error_index\u001b[90m\u001b[39;49;00m\n",
            "        msg += original_trace\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m ProcessRaisedException(msg, error_index, failed_process.pid)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       torch.multiprocessing.spawn.ProcessRaisedException: \u001b[0m\n",
            "\u001b[1m\u001b[31mE       \u001b[0m\n",
            "\u001b[1m\u001b[31mE       -- Process 1 terminated with the following error:\u001b[0m\n",
            "\u001b[1m\u001b[31mE       Traceback (most recent call last):\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\u001b[0m\n",
            "\u001b[1m\u001b[31mE           fn(i, *args)\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/test_ddp.py\", line 75, in _test_DistributedDataParallelCPU\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ddp_model = get_ddp_bucketed(\u001b[0m\n",
            "\u001b[1m\u001b[31mE                       ^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/adapters.py\", line 138, in get_ddp_bucketed\u001b[0m\n",
            "\u001b[1m\u001b[31mE           raise NotImplementedError\u001b[0m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:158: ProcessRaisedException\n",
            "----------------------------- Captured stderr call -----------------------------\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\u001b[31m\u001b[1m_______ test_DistributedDataParallelCPU[0.0001-ToyModelWithTiedWeights] ________\u001b[0m\n",
            "\n",
            "bucket_size_mb = 0.0001\n",
            "model_class = <class 'tests.common.ToyModelWithTiedWeights'>\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_class\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [ToyModel, ToyModelWithTiedWeights])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbucket_size_mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94m0.0016\u001b[39;49;00m, \u001b[94m0.0001\u001b[39;49;00m, \u001b[94m0.01\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_DistributedDataParallelCPU\u001b[39;49;00m(bucket_size_mb, model_class):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.0016 is designed to test the case with 2 buckets (one bucket\u001b[39;49;00m\n",
            "    \u001b[33m    has 2 parameter tensors, the other has 2).\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.0001 is designed to test the case with 3 buckets (each bucket\u001b[39;49;00m\n",
            "    \u001b[33m    has one parameter tensors).\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.01 is designed to test the case with 1 buckets (containing\u001b[39;49;00m\n",
            "    \u001b[33m    3 parameter tensors).\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        world_size = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       mp.spawn(\u001b[90m\u001b[39;49;00m\n",
            "            _test_DistributedDataParallelCPU,\u001b[90m\u001b[39;49;00m\n",
            "            args=(world_size, bucket_size_mb, model_class),\u001b[90m\u001b[39;49;00m\n",
            "            nprocs=world_size,\u001b[90m\u001b[39;49;00m\n",
            "            join=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mcs336-systems/tests/test_ddp.py\u001b[0m:44: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:241: in spawn\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m start_processes(fn, args, nprocs, join, daemon, start_method=\u001b[33m\"\u001b[39;49;00m\u001b[33mspawn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:197: in start_processes\n",
            "    \u001b[0m\u001b[94mwhile\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m context.join():\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <torch.multiprocessing.spawn.ProcessContext object at 0x78645acec310>\n",
            "timeout = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mjoin\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, timeout=\u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\"\"Join one or more processes within spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Attempt to join one or more processes in this spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m    If one of them exited with a non-zero exit status, this function\u001b[39;49;00m\n",
            "    \u001b[33m    kills the remaining processes and raises an exception with the cause\u001b[39;49;00m\n",
            "    \u001b[33m    of the first process exiting.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Returns ``True`` if all processes have been joined successfully,\u001b[39;49;00m\n",
            "    \u001b[33m    ``False`` if there are more processes that need to be joined.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Args:\u001b[39;49;00m\n",
            "    \u001b[33m        timeout (float): Wait this long before giving up on waiting.\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Ensure this function can be called even when we're done.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Wait for any process to fail or all of them to succeed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ready = multiprocessing.connection.wait(\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[96mself\u001b[39;49;00m.sentinels.keys(),\u001b[90m\u001b[39;49;00m\n",
            "            timeout=timeout,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        error_index = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m sentinel \u001b[95min\u001b[39;49;00m ready:\u001b[90m\u001b[39;49;00m\n",
            "            index = \u001b[96mself\u001b[39;49;00m.sentinels.pop(sentinel)\u001b[90m\u001b[39;49;00m\n",
            "            process = \u001b[96mself\u001b[39;49;00m.processes[index]\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.exitcode != \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                error_index = index\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mbreak\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Return if there was no error.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m error_index \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# Return whether or not all processes have been joined.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Assume failure. Terminate processes that are still alive.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
            "                process.terminate()\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# There won't be an error on the queue if the process crashed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        failed_process = \u001b[96mself\u001b[39;49;00m.processes[error_index]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.error_queues[error_index].empty():\u001b[90m\u001b[39;49;00m\n",
            "            exitcode = \u001b[96mself\u001b[39;49;00m.processes[error_index].exitcode\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m exitcode < \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                name = signal.Signals(-exitcode).name\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with signal \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, name),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                    signal_name=name,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with exit code \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, exitcode),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        original_trace = \u001b[96mself\u001b[39;49;00m.error_queues[error_index].get()\u001b[90m\u001b[39;49;00m\n",
            "        msg = \u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m-- Process \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with the following error:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % error_index\u001b[90m\u001b[39;49;00m\n",
            "        msg += original_trace\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m ProcessRaisedException(msg, error_index, failed_process.pid)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       torch.multiprocessing.spawn.ProcessRaisedException: \u001b[0m\n",
            "\u001b[1m\u001b[31mE       \u001b[0m\n",
            "\u001b[1m\u001b[31mE       -- Process 1 terminated with the following error:\u001b[0m\n",
            "\u001b[1m\u001b[31mE       Traceback (most recent call last):\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\u001b[0m\n",
            "\u001b[1m\u001b[31mE           fn(i, *args)\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/test_ddp.py\", line 75, in _test_DistributedDataParallelCPU\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ddp_model = get_ddp_bucketed(\u001b[0m\n",
            "\u001b[1m\u001b[31mE                       ^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/adapters.py\", line 138, in get_ddp_bucketed\u001b[0m\n",
            "\u001b[1m\u001b[31mE           raise NotImplementedError\u001b[0m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:158: ProcessRaisedException\n",
            "----------------------------- Captured stderr call -----------------------------\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\u001b[31m\u001b[1m________________ test_DistributedDataParallelCPU[0.01-ToyModel] ________________\u001b[0m\n",
            "\n",
            "bucket_size_mb = 0.01, model_class = <class 'tests.common.ToyModel'>\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_class\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [ToyModel, ToyModelWithTiedWeights])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbucket_size_mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94m0.0016\u001b[39;49;00m, \u001b[94m0.0001\u001b[39;49;00m, \u001b[94m0.01\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_DistributedDataParallelCPU\u001b[39;49;00m(bucket_size_mb, model_class):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.0016 is designed to test the case with 2 buckets (one bucket\u001b[39;49;00m\n",
            "    \u001b[33m    has 2 parameter tensors, the other has 2).\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.0001 is designed to test the case with 3 buckets (each bucket\u001b[39;49;00m\n",
            "    \u001b[33m    has one parameter tensors).\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.01 is designed to test the case with 1 buckets (containing\u001b[39;49;00m\n",
            "    \u001b[33m    3 parameter tensors).\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        world_size = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       mp.spawn(\u001b[90m\u001b[39;49;00m\n",
            "            _test_DistributedDataParallelCPU,\u001b[90m\u001b[39;49;00m\n",
            "            args=(world_size, bucket_size_mb, model_class),\u001b[90m\u001b[39;49;00m\n",
            "            nprocs=world_size,\u001b[90m\u001b[39;49;00m\n",
            "            join=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mcs336-systems/tests/test_ddp.py\u001b[0m:44: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:241: in spawn\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m start_processes(fn, args, nprocs, join, daemon, start_method=\u001b[33m\"\u001b[39;49;00m\u001b[33mspawn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:197: in start_processes\n",
            "    \u001b[0m\u001b[94mwhile\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m context.join():\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <torch.multiprocessing.spawn.ProcessContext object at 0x78645ae93550>\n",
            "timeout = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mjoin\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, timeout=\u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\"\"Join one or more processes within spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Attempt to join one or more processes in this spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m    If one of them exited with a non-zero exit status, this function\u001b[39;49;00m\n",
            "    \u001b[33m    kills the remaining processes and raises an exception with the cause\u001b[39;49;00m\n",
            "    \u001b[33m    of the first process exiting.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Returns ``True`` if all processes have been joined successfully,\u001b[39;49;00m\n",
            "    \u001b[33m    ``False`` if there are more processes that need to be joined.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Args:\u001b[39;49;00m\n",
            "    \u001b[33m        timeout (float): Wait this long before giving up on waiting.\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Ensure this function can be called even when we're done.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Wait for any process to fail or all of them to succeed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ready = multiprocessing.connection.wait(\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[96mself\u001b[39;49;00m.sentinels.keys(),\u001b[90m\u001b[39;49;00m\n",
            "            timeout=timeout,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        error_index = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m sentinel \u001b[95min\u001b[39;49;00m ready:\u001b[90m\u001b[39;49;00m\n",
            "            index = \u001b[96mself\u001b[39;49;00m.sentinels.pop(sentinel)\u001b[90m\u001b[39;49;00m\n",
            "            process = \u001b[96mself\u001b[39;49;00m.processes[index]\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.exitcode != \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                error_index = index\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mbreak\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Return if there was no error.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m error_index \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# Return whether or not all processes have been joined.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Assume failure. Terminate processes that are still alive.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
            "                process.terminate()\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# There won't be an error on the queue if the process crashed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        failed_process = \u001b[96mself\u001b[39;49;00m.processes[error_index]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.error_queues[error_index].empty():\u001b[90m\u001b[39;49;00m\n",
            "            exitcode = \u001b[96mself\u001b[39;49;00m.processes[error_index].exitcode\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m exitcode < \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                name = signal.Signals(-exitcode).name\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with signal \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, name),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                    signal_name=name,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with exit code \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, exitcode),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        original_trace = \u001b[96mself\u001b[39;49;00m.error_queues[error_index].get()\u001b[90m\u001b[39;49;00m\n",
            "        msg = \u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m-- Process \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with the following error:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % error_index\u001b[90m\u001b[39;49;00m\n",
            "        msg += original_trace\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m ProcessRaisedException(msg, error_index, failed_process.pid)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       torch.multiprocessing.spawn.ProcessRaisedException: \u001b[0m\n",
            "\u001b[1m\u001b[31mE       \u001b[0m\n",
            "\u001b[1m\u001b[31mE       -- Process 0 terminated with the following error:\u001b[0m\n",
            "\u001b[1m\u001b[31mE       Traceback (most recent call last):\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\u001b[0m\n",
            "\u001b[1m\u001b[31mE           fn(i, *args)\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/test_ddp.py\", line 75, in _test_DistributedDataParallelCPU\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ddp_model = get_ddp_bucketed(\u001b[0m\n",
            "\u001b[1m\u001b[31mE                       ^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/adapters.py\", line 138, in get_ddp_bucketed\u001b[0m\n",
            "\u001b[1m\u001b[31mE           raise NotImplementedError\u001b[0m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:158: ProcessRaisedException\n",
            "----------------------------- Captured stderr call -----------------------------\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:12355 (errno: 99 - Cannot assign requested address).\n",
            "\u001b[31m\u001b[1m________ test_DistributedDataParallelCPU[0.01-ToyModelWithTiedWeights] _________\u001b[0m\n",
            "\n",
            "bucket_size_mb = 0.01\n",
            "model_class = <class 'tests.common.ToyModelWithTiedWeights'>\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_class\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [ToyModel, ToyModelWithTiedWeights])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbucket_size_mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94m0.0016\u001b[39;49;00m, \u001b[94m0.0001\u001b[39;49;00m, \u001b[94m0.01\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_DistributedDataParallelCPU\u001b[39;49;00m(bucket_size_mb, model_class):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.0016 is designed to test the case with 2 buckets (one bucket\u001b[39;49;00m\n",
            "    \u001b[33m    has 2 parameter tensors, the other has 2).\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.0001 is designed to test the case with 3 buckets (each bucket\u001b[39;49;00m\n",
            "    \u001b[33m    has one parameter tensors).\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    bucket_size_mb 0.01 is designed to test the case with 1 buckets (containing\u001b[39;49;00m\n",
            "    \u001b[33m    3 parameter tensors).\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        world_size = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       mp.spawn(\u001b[90m\u001b[39;49;00m\n",
            "            _test_DistributedDataParallelCPU,\u001b[90m\u001b[39;49;00m\n",
            "            args=(world_size, bucket_size_mb, model_class),\u001b[90m\u001b[39;49;00m\n",
            "            nprocs=world_size,\u001b[90m\u001b[39;49;00m\n",
            "            join=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mcs336-systems/tests/test_ddp.py\u001b[0m:44: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:241: in spawn\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m start_processes(fn, args, nprocs, join, daemon, start_method=\u001b[33m\"\u001b[39;49;00m\u001b[33mspawn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:197: in start_processes\n",
            "    \u001b[0m\u001b[94mwhile\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m context.join():\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <torch.multiprocessing.spawn.ProcessContext object at 0x78645feebbd0>\n",
            "timeout = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mjoin\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, timeout=\u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\"\"Join one or more processes within spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Attempt to join one or more processes in this spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m    If one of them exited with a non-zero exit status, this function\u001b[39;49;00m\n",
            "    \u001b[33m    kills the remaining processes and raises an exception with the cause\u001b[39;49;00m\n",
            "    \u001b[33m    of the first process exiting.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Returns ``True`` if all processes have been joined successfully,\u001b[39;49;00m\n",
            "    \u001b[33m    ``False`` if there are more processes that need to be joined.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Args:\u001b[39;49;00m\n",
            "    \u001b[33m        timeout (float): Wait this long before giving up on waiting.\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Ensure this function can be called even when we're done.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Wait for any process to fail or all of them to succeed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ready = multiprocessing.connection.wait(\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[96mself\u001b[39;49;00m.sentinels.keys(),\u001b[90m\u001b[39;49;00m\n",
            "            timeout=timeout,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        error_index = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m sentinel \u001b[95min\u001b[39;49;00m ready:\u001b[90m\u001b[39;49;00m\n",
            "            index = \u001b[96mself\u001b[39;49;00m.sentinels.pop(sentinel)\u001b[90m\u001b[39;49;00m\n",
            "            process = \u001b[96mself\u001b[39;49;00m.processes[index]\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.exitcode != \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                error_index = index\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mbreak\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Return if there was no error.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m error_index \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# Return whether or not all processes have been joined.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Assume failure. Terminate processes that are still alive.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
            "                process.terminate()\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# There won't be an error on the queue if the process crashed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        failed_process = \u001b[96mself\u001b[39;49;00m.processes[error_index]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.error_queues[error_index].empty():\u001b[90m\u001b[39;49;00m\n",
            "            exitcode = \u001b[96mself\u001b[39;49;00m.processes[error_index].exitcode\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m exitcode < \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                name = signal.Signals(-exitcode).name\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with signal \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, name),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                    signal_name=name,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with exit code \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, exitcode),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        original_trace = \u001b[96mself\u001b[39;49;00m.error_queues[error_index].get()\u001b[90m\u001b[39;49;00m\n",
            "        msg = \u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m-- Process \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with the following error:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % error_index\u001b[90m\u001b[39;49;00m\n",
            "        msg += original_trace\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m ProcessRaisedException(msg, error_index, failed_process.pid)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       torch.multiprocessing.spawn.ProcessRaisedException: \u001b[0m\n",
            "\u001b[1m\u001b[31mE       \u001b[0m\n",
            "\u001b[1m\u001b[31mE       -- Process 1 terminated with the following error:\u001b[0m\n",
            "\u001b[1m\u001b[31mE       Traceback (most recent call last):\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\u001b[0m\n",
            "\u001b[1m\u001b[31mE           fn(i, *args)\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/test_ddp.py\", line 75, in _test_DistributedDataParallelCPU\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ddp_model = get_ddp_bucketed(\u001b[0m\n",
            "\u001b[1m\u001b[31mE                       ^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/adapters.py\", line 138, in get_ddp_bucketed\u001b[0m\n",
            "\u001b[1m\u001b[31mE           raise NotImplementedError\u001b[0m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:158: ProcessRaisedException\n",
            "----------------------------- Captured stderr call -----------------------------\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\u001b[31m\u001b[1m_______________________ test_sharded_optimizer[ToyModel] _______________________\u001b[0m\n",
            "\n",
            "model_class = <class 'tests.common.ToyModel'>\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_class\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [ToyModel, ToyModelWithTiedWeights])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_sharded_optimizer\u001b[39;49;00m(model_class):\u001b[90m\u001b[39;49;00m\n",
            "        world_size = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       mp.spawn(\u001b[90m\u001b[39;49;00m\n",
            "            _test_sharded_optimizer,\u001b[90m\u001b[39;49;00m\n",
            "            args=(world_size, model_class),\u001b[90m\u001b[39;49;00m\n",
            "            nprocs=world_size,\u001b[90m\u001b[39;49;00m\n",
            "            join=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mcs336-systems/tests/test_sharded_optimizer.py\u001b[0m:22: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:241: in spawn\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m start_processes(fn, args, nprocs, join, daemon, start_method=\u001b[33m\"\u001b[39;49;00m\u001b[33mspawn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:197: in start_processes\n",
            "    \u001b[0m\u001b[94mwhile\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m context.join():\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <torch.multiprocessing.spawn.ProcessContext object at 0x786459942990>\n",
            "timeout = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mjoin\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, timeout=\u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\"\"Join one or more processes within spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Attempt to join one or more processes in this spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m    If one of them exited with a non-zero exit status, this function\u001b[39;49;00m\n",
            "    \u001b[33m    kills the remaining processes and raises an exception with the cause\u001b[39;49;00m\n",
            "    \u001b[33m    of the first process exiting.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Returns ``True`` if all processes have been joined successfully,\u001b[39;49;00m\n",
            "    \u001b[33m    ``False`` if there are more processes that need to be joined.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Args:\u001b[39;49;00m\n",
            "    \u001b[33m        timeout (float): Wait this long before giving up on waiting.\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Ensure this function can be called even when we're done.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Wait for any process to fail or all of them to succeed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ready = multiprocessing.connection.wait(\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[96mself\u001b[39;49;00m.sentinels.keys(),\u001b[90m\u001b[39;49;00m\n",
            "            timeout=timeout,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        error_index = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m sentinel \u001b[95min\u001b[39;49;00m ready:\u001b[90m\u001b[39;49;00m\n",
            "            index = \u001b[96mself\u001b[39;49;00m.sentinels.pop(sentinel)\u001b[90m\u001b[39;49;00m\n",
            "            process = \u001b[96mself\u001b[39;49;00m.processes[index]\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.exitcode != \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                error_index = index\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mbreak\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Return if there was no error.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m error_index \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# Return whether or not all processes have been joined.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Assume failure. Terminate processes that are still alive.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
            "                process.terminate()\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# There won't be an error on the queue if the process crashed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        failed_process = \u001b[96mself\u001b[39;49;00m.processes[error_index]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.error_queues[error_index].empty():\u001b[90m\u001b[39;49;00m\n",
            "            exitcode = \u001b[96mself\u001b[39;49;00m.processes[error_index].exitcode\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m exitcode < \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                name = signal.Signals(-exitcode).name\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with signal \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, name),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                    signal_name=name,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with exit code \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, exitcode),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        original_trace = \u001b[96mself\u001b[39;49;00m.error_queues[error_index].get()\u001b[90m\u001b[39;49;00m\n",
            "        msg = \u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m-- Process \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with the following error:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % error_index\u001b[90m\u001b[39;49;00m\n",
            "        msg += original_trace\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m ProcessRaisedException(msg, error_index, failed_process.pid)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       torch.multiprocessing.spawn.ProcessRaisedException: \u001b[0m\n",
            "\u001b[1m\u001b[31mE       \u001b[0m\n",
            "\u001b[1m\u001b[31mE       -- Process 1 terminated with the following error:\u001b[0m\n",
            "\u001b[1m\u001b[31mE       Traceback (most recent call last):\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\u001b[0m\n",
            "\u001b[1m\u001b[31mE           fn(i, *args)\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/test_sharded_optimizer.py\", line 48, in _test_sharded_optimizer\u001b[0m\n",
            "\u001b[1m\u001b[31mE           sharded_optimizer = get_sharded_optimizer(\u001b[0m\n",
            "\u001b[1m\u001b[31mE                               ^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/adapters.py\", line 191, in get_sharded_optimizer\u001b[0m\n",
            "\u001b[1m\u001b[31mE           raise NotImplementedError\u001b[0m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:158: ProcessRaisedException\n",
            "----------------------------- Captured stderr call -----------------------------\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\u001b[31m\u001b[1m_______________ test_sharded_optimizer[ToyModelWithTiedWeights] ________________\u001b[0m\n",
            "\n",
            "model_class = <class 'tests.common.ToyModelWithTiedWeights'>\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_class\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [ToyModel, ToyModelWithTiedWeights])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_sharded_optimizer\u001b[39;49;00m(model_class):\u001b[90m\u001b[39;49;00m\n",
            "        world_size = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       mp.spawn(\u001b[90m\u001b[39;49;00m\n",
            "            _test_sharded_optimizer,\u001b[90m\u001b[39;49;00m\n",
            "            args=(world_size, model_class),\u001b[90m\u001b[39;49;00m\n",
            "            nprocs=world_size,\u001b[90m\u001b[39;49;00m\n",
            "            join=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mcs336-systems/tests/test_sharded_optimizer.py\u001b[0m:22: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:241: in spawn\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m start_processes(fn, args, nprocs, join, daemon, start_method=\u001b[33m\"\u001b[39;49;00m\u001b[33mspawn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:197: in start_processes\n",
            "    \u001b[0m\u001b[94mwhile\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m context.join():\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <torch.multiprocessing.spawn.ProcessContext object at 0x7864599a98d0>\n",
            "timeout = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mjoin\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, timeout=\u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\"\"Join one or more processes within spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Attempt to join one or more processes in this spawn context.\u001b[39;49;00m\n",
            "    \u001b[33m    If one of them exited with a non-zero exit status, this function\u001b[39;49;00m\n",
            "    \u001b[33m    kills the remaining processes and raises an exception with the cause\u001b[39;49;00m\n",
            "    \u001b[33m    of the first process exiting.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Returns ``True`` if all processes have been joined successfully,\u001b[39;49;00m\n",
            "    \u001b[33m    ``False`` if there are more processes that need to be joined.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Args:\u001b[39;49;00m\n",
            "    \u001b[33m        timeout (float): Wait this long before giving up on waiting.\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Ensure this function can be called even when we're done.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Wait for any process to fail or all of them to succeed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ready = multiprocessing.connection.wait(\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[96mself\u001b[39;49;00m.sentinels.keys(),\u001b[90m\u001b[39;49;00m\n",
            "            timeout=timeout,\u001b[90m\u001b[39;49;00m\n",
            "        )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        error_index = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m sentinel \u001b[95min\u001b[39;49;00m ready:\u001b[90m\u001b[39;49;00m\n",
            "            index = \u001b[96mself\u001b[39;49;00m.sentinels.pop(sentinel)\u001b[90m\u001b[39;49;00m\n",
            "            process = \u001b[96mself\u001b[39;49;00m.processes[index]\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.exitcode != \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                error_index = index\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mbreak\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Return if there was no error.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m error_index \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# Return whether or not all processes have been joined.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Assume failure. Terminate processes that are still alive.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
            "                process.terminate()\u001b[90m\u001b[39;49;00m\n",
            "            process.join()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# There won't be an error on the queue if the process crashed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        failed_process = \u001b[96mself\u001b[39;49;00m.processes[error_index]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.error_queues[error_index].empty():\u001b[90m\u001b[39;49;00m\n",
            "            exitcode = \u001b[96mself\u001b[39;49;00m.processes[error_index].exitcode\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m exitcode < \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                name = signal.Signals(-exitcode).name\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with signal \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, name),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                    signal_name=name,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with exit code \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (error_index, exitcode),\u001b[90m\u001b[39;49;00m\n",
            "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
            "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
            "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        original_trace = \u001b[96mself\u001b[39;49;00m.error_queues[error_index].get()\u001b[90m\u001b[39;49;00m\n",
            "        msg = \u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m-- Process \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m terminated with the following error:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % error_index\u001b[90m\u001b[39;49;00m\n",
            "        msg += original_trace\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m ProcessRaisedException(msg, error_index, failed_process.pid)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       torch.multiprocessing.spawn.ProcessRaisedException: \u001b[0m\n",
            "\u001b[1m\u001b[31mE       \u001b[0m\n",
            "\u001b[1m\u001b[31mE       -- Process 0 terminated with the following error:\u001b[0m\n",
            "\u001b[1m\u001b[31mE       Traceback (most recent call last):\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\u001b[0m\n",
            "\u001b[1m\u001b[31mE           fn(i, *args)\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/test_sharded_optimizer.py\", line 48, in _test_sharded_optimizer\u001b[0m\n",
            "\u001b[1m\u001b[31mE           sharded_optimizer = get_sharded_optimizer(\u001b[0m\n",
            "\u001b[1m\u001b[31mE                               ^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[1m\u001b[31mE         File \"/content/s2025-assignment4-hpc/cs336-systems/tests/adapters.py\", line 191, in get_sharded_optimizer\u001b[0m\n",
            "\u001b[1m\u001b[31mE           raise NotImplementedError\u001b[0m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m:158: ProcessRaisedException\n",
            "----------------------------- Captured stderr call -----------------------------\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
            "../../usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20\n",
            "  /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m cs336-systems/tests/test_ddp.py::\u001b[1mtest_DistributedDataParallelCPU[0.0016-ToyModel]\u001b[0m - torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\u001b[31mFAILED\u001b[0m cs336-systems/tests/test_ddp.py::\u001b[1mtest_DistributedDataParallelCPU[0.0016-ToyModelWithTiedWeights]\u001b[0m - torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\u001b[31mFAILED\u001b[0m cs336-systems/tests/test_ddp.py::\u001b[1mtest_DistributedDataParallelCPU[0.0001-ToyModel]\u001b[0m - torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\u001b[31mFAILED\u001b[0m cs336-systems/tests/test_ddp.py::\u001b[1mtest_DistributedDataParallelCPU[0.0001-ToyModelWithTiedWeights]\u001b[0m - torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\u001b[31mFAILED\u001b[0m cs336-systems/tests/test_ddp.py::\u001b[1mtest_DistributedDataParallelCPU[0.01-ToyModel]\u001b[0m - torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\u001b[31mFAILED\u001b[0m cs336-systems/tests/test_ddp.py::\u001b[1mtest_DistributedDataParallelCPU[0.01-ToyModelWithTiedWeights]\u001b[0m - torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\u001b[31mFAILED\u001b[0m cs336-systems/tests/test_sharded_optimizer.py::\u001b[1mtest_sharded_optimizer[ToyModel]\u001b[0m - torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\u001b[31mFAILED\u001b[0m cs336-systems/tests/test_sharded_optimizer.py::\u001b[1mtest_sharded_optimizer[ToyModelWithTiedWeights]\u001b[0m - torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\u001b[31m========= \u001b[31m\u001b[1m8 failed\u001b[0m, \u001b[32m6 passed\u001b[0m, \u001b[33m4 skipped\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 71.62s (0:01:11)\u001b[0m\u001b[31m =========\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}